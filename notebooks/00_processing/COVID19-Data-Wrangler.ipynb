{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 Data Collection\n",
    "\n",
    "Authors (in alphabetical order): Frederic Poitevin, Joao Rodrigues, Andrea Scaiewicz\n",
    "\n",
    "This notebook pulls and merges data from several sources to create a standardized format for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pathlib\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = pathlib.Path('..') / '..' / 'output'  # directory where final csv file is written to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst_tz = datetime.timezone(datetime.timedelta(hours=-7))  # define the timezone\n",
    "\n",
    "# Generate date stamps from 1/22/2020 until yesterday\n",
    "start_date = datetime.datetime(2020, 1, 23).astimezone(pst_tz)  # offset for PST\n",
    "\n",
    "today_date = datetime.datetime.now(datetime.timezone.utc).astimezone(pst_tz)\n",
    "end_date = (today_date - datetime.timedelta(days=1))\n",
    "\n",
    "dates_cols = [\n",
    "    f'{d.month}/{d.day}/{str(d.year)[2:]}'  # date format should be e.g. 1/7/20 (July 1st, 2020)\n",
    "    for d in pd.date_range(start_date, end_date)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__World Data__\n",
    "\n",
    "First, we get raw data from JHU (source: https://github.com/CSSEGISandData/COVID-19/). JHU stores data for country-level data for confirmed and deaths in separate files. We need to merge these into one coherent file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jhu_country_level_data(url):\n",
    "    \n",
    "    # Define which columns we want to read\n",
    "    columns = {\n",
    "        'Province/State' : str,\n",
    "        'Country/Region': str\n",
    "    }\n",
    "\n",
    "    columns.update(\n",
    "        {k: int for k in dates_cols}\n",
    "    )\n",
    "    \n",
    "    df = pd.read_csv(\n",
    "        url,\n",
    "        usecols=list(columns.keys()),\n",
    "        dtype=columns  # Specify dtype to save memory on load and check for bad values\n",
    "    )\n",
    "    \n",
    "    df.rename(\n",
    "        {\n",
    "            'Country/Region': 'Country_Region',\n",
    "            'Province/State': 'Province_State'\n",
    "        },\n",
    "        axis=1,\n",
    "        inplace=True\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\"\n",
    "df_confirmed = read_jhu_country_level_data(confirmed_url)\n",
    "df_confirmed.insert(loc=2, column='Case_Type', value='Confirmed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv\"\n",
    "df_deaths = read_jhu_country_level_data(death_url)\n",
    "df_deaths.insert(loc=2, column='Case_Type', value='Deaths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df_deaths) == len(df_confirmed) # sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_countries = df_confirmed.append(df_deaths)\n",
    "df_countries.sort_values(by=['Country_Region', 'Province_State'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__US State/County Data__\n",
    "\n",
    "We get raw data from JHU (source: https://github.com/CSSEGISandData/COVID-19/). JHU stores data for county-level data for confirmed and deaths in separate files. We need to merge these into one file again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jhu_US_county_level_data(url):\n",
    "    \n",
    "    # Define which columns we want to read\n",
    "    columns = {\n",
    "        'Province_State' : str,\n",
    "        'Country_Region': str,\n",
    "        'Admin2': str,\n",
    "    }\n",
    "\n",
    "    columns.update(\n",
    "        {k: int for k in dates_cols}\n",
    "    )\n",
    "    \n",
    "    df = pd.read_csv(\n",
    "        url,\n",
    "        usecols=list(columns.keys()),\n",
    "        dtype=columns  # Specify dtype to save memory on load and check for bad values\n",
    "    )\n",
    "    \n",
    "    df.rename(\n",
    "        {\n",
    "            'Admin2': 'County_Name',\n",
    "        },\n",
    "        axis=1,\n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_confirmed_url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv\"\n",
    "df_us_confirmed = read_jhu_US_county_level_data(us_confirmed_url)\n",
    "df_us_confirmed.insert(loc=4, column='Case_Type', value='Confirmed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_death_url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv\"\n",
    "df_us_deaths = read_jhu_US_county_level_data(us_death_url)\n",
    "df_us_deaths.insert(loc=4, column='Case_Type', value='Deaths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df_us_confirmed) == len(df_us_deaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_counties = df_us_confirmed.append(df_us_deaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Merge JHU Datasets__\n",
    "\n",
    "Now we need to merge JHU datasets, making sure the columns align properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add extra columns in df_us_counties to df_countries\n",
    "df_countries['County_Name'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the total of the US from the world data\n",
    "mask = df_countries['Country_Region'] == 'US'\n",
    "df_countries = df_countries[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jhu_combined = df_countries.append(df_us_counties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jhu_combined['Source'] = 'jhu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Italian Regional Data__\n",
    "\n",
    "We get data for Italian Regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_italy = \"https://raw.githubusercontent.com/pcm-dpc/COVID-19/master/dati-regioni/dpc-covid19-ita-regioni.csv\"\n",
    "df_italy = pd.read_csv(url_italy)\n",
    "\n",
    "to_keep = set(('deceduti', 'totale_casi', 'data', 'denominazione_regione'))\n",
    "to_drop = [c for c in df_italy.columns if c not in to_keep]\n",
    "df_italy.drop(\n",
    "    columns=to_drop,\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# First, we translate the column labels and get rid of the unimportant ones.\n",
    "# A region - _regione_ - is the equivalent of a Province in the JHU dataset.\n",
    "\n",
    "df_italy.rename(\n",
    "    columns={\n",
    "        \"data\": \"Date\",\n",
    "        \"denominazione_regione\": \"Province/State\",\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "df_italy.rename(\n",
    "    columns={\n",
    "        \"Province/State\": \"Province_State\",\n",
    "        \"totale_casi\": \"Confirmed\",\n",
    "        \"deceduti\": \"Deaths\"\n",
    "    },\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Italy dataframe is missing dates. We need to add the missing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we identify and match dates\n",
    "raw_italy_dates = [\n",
    "    t.replace(hour=0, minute=0, second=0)\n",
    "    for t in pd.to_datetime(df_italy['Date'].unique())\n",
    "]\n",
    "\n",
    "# Add non-existing dates (from Jan 21st)\n",
    "start_date = datetime.datetime(2020, 1, 22)\n",
    "end_date = datetime.datetime.today() - datetime.timedelta(days=1)\n",
    "missing_dates = [\n",
    "    i for i in pd.date_range(start_date, end_date)\n",
    "    if i not in raw_italy_dates\n",
    "]\n",
    "\n",
    "italy_dates = [\n",
    "    f'{d.month}/{d.day}/{str(d.year)[2:]}'\n",
    "    for d in missing_dates + raw_italy_dates\n",
    "]\n",
    "\n",
    "date_to_idx = {\n",
    "    d: idx for idx, d in enumerate(italy_dates)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to flip the Italy dataframe, to match JHU format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provinces = list(df_italy['Province_State'].unique())\n",
    "\n",
    "datadict = {\n",
    "    p: {\n",
    "        'Confirmed': [0 for d in italy_dates],\n",
    "        'Deaths': [0 for d in italy_dates]\n",
    "    }\n",
    "    for p in provinces\n",
    "}  # province -> cases\n",
    "\n",
    "for row_idx in range(len(df_italy)):\n",
    "    date, province, deaths, confirmed = df_italy.iloc[row_idx].to_list()\n",
    "    assert deaths <= confirmed  # sanity check\n",
    "    \n",
    "    d = pd.to_datetime(date)\n",
    "    date_as_str = f'{d.month}/{d.day}/{str(d.year)[2:]}'\n",
    "    date_idx = date_to_idx[date_as_str]\n",
    "    \n",
    "    datadict[province]['Confirmed'][date_idx] = confirmed\n",
    "    datadict[province]['Deaths'][date_idx] = deaths\n",
    "\n",
    "data_rows = [\n",
    "    [p, 'Confirmed'] + datadict[p]['Confirmed']\n",
    "    for p in datadict\n",
    "]\n",
    "data_rows.extend([\n",
    "    [p, 'Deaths'] + datadict[p]['Deaths']\n",
    "    for p in datadict\n",
    "])\n",
    "\n",
    "df_italy_T = pd.DataFrame.from_records(\n",
    "    data_rows,\n",
    "    columns=[\n",
    "        'Province_State',\n",
    "        'Case_Type',\n",
    "    ] + italy_dates\n",
    ")\n",
    "\n",
    "df_italy_T.sort_values(['Province_State', 'Case_Type'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Country_Region, County, and Source columns to match JHU\n",
    "df_italy_T['Country_Region'] = 'Italy'\n",
    "df_italy_T['County_Name'] = ''  # Empty\n",
    "df_italy_T['Source'] = 'dpc-covid19-ita-province'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the total of Italy from the world data\n",
    "mask = df_jhu_combined['Country_Region'] == 'Italy'\n",
    "df_jhu_combined = df_jhu_combined[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = df_jhu_combined.append(df_italy_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Standardize Names__\n",
    "\n",
    "Country names have non-standard characters that may not work well as filenames. Let's standardize that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_name(name):\n",
    "    \"\"\"Replaces all non-alphanumerical characters by underscores\"\"\"\n",
    "    if not pd.isnull(name):\n",
    "        return re.sub('[^A-Za-z0-9_]+', '_', name).strip('_')\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for colname in ['Country_Region', 'Province_State', 'County_Name']:\n",
    "    col_safe_name = colname + '_Safe'\n",
    "    df_combined[col_safe_name] = df_combined[colname].apply(sanitize_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Final Preparations & Saving__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a timestamp column with last update date (UTC timezone)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined[\"Last_Update_Date\"] = datetime.datetime.utcnow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort dataframe by country, then province, then county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.sort_values(\n",
    "    by=['Country_Region', 'Province_State', 'County_Name', 'Case_Type'],\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write result dataframe to disk as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv(\n",
    "    str(output_dir / \"Data_COVID-19_v2.csv\"),  # Path to str\n",
    "    index=False,\n",
    "    columns=[\n",
    "        \"Country_Region\",\n",
    "        \"Country_Region_Safe\",\n",
    "        \"Province_State\",\n",
    "        \"Province_State_Safe\",\n",
    "        \"County_Name\",\n",
    "        \"County_Name_Safe\",\n",
    "        \"Case_Type\",\n",
    "        \"Source\",\n",
    "        \"Last_Update_Date\"\n",
    "    ] + dates_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Aggregate Data at Country/State Level__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df_combined.groupby(\n",
    "    [\n",
    "        'Country_Region', \n",
    "        'Country_Region_Safe',\n",
    "        'Case_Type',\n",
    "        'Source',\n",
    "        'Last_Update_Date'\n",
    "    ]\n",
    ")\n",
    "df_bycountry = groups.sum().reset_index()\n",
    "\n",
    "df_bycountry.to_csv(\n",
    "    str(output_dir / \"Data_COVID-19_v2_bycountry.csv\"),  # Path to str\n",
    "    index=False,\n",
    "    columns=[\n",
    "        \"Country_Region\",\n",
    "        \"Country_Region_Safe\",\n",
    "        \"Case_Type\",\n",
    "        \"Source\",\n",
    "        \"Last_Update_Date\"\n",
    "    ] + dates_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df_combined.groupby(\n",
    "    [\n",
    "        'Country_Region', \n",
    "        'Country_Region_Safe',\n",
    "        'Province_State',\n",
    "        'Province_State_Safe',\n",
    "        'County_Name',       \n",
    "        'County_Name_Safe',\n",
    "        'Case_Type',\n",
    "        'Source',\n",
    "        'Last_Update_Date'\n",
    "    ]\n",
    ")\n",
    "df_bystate = groups.sum().reset_index()\n",
    "\n",
    "df_bystate.to_csv(\n",
    "    str(output_dir / \"Data_COVID-19_v2_bystate.csv\"),  # Path to str\n",
    "    index=False,\n",
    "    columns=[\n",
    "        \"Country_Region\",\n",
    "        \"Country_Region_Safe\",\n",
    "        \"Province_State\",\n",
    "        \"Province_State_Safe\",\n",
    "        \"County_Name\",       \n",
    "        \"County_Name_Safe\",\n",
    "        \"Case_Type\",\n",
    "        \"Source\",\n",
    "        \"Last_Update_Date\"\n",
    "    ] + dates_cols\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
